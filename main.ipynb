{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "train = pd.read_csv('labeledTrainData.tsv',header=0,delimiter='\\t',quoting=3)\n",
    "ex1 = BeautifulSoup(train[\"review\"][0])\n",
    "#print train.info\n",
    "#print train[\"review\"][0]\n",
    "#print ex1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity we're going to trim down the reviews to just letters, ignoring symbols and numbers for now. To do this we'll use the regex library re and then we'll tokenise the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With all this stuff going down at the moment with\n",
      "\n",
      "[u'with', u'all', u'this', u'stuff', u'going', u'down', u'at', u'the', u'moment', u'with', u'mj', u'i', u've', u'started', u'listening', u'to', u'his', u'music', u'watching', u'the']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Use regular expressions to do a find-and-replace:\n",
    "# Find anything that is NOT a lowercase letter (a-z)\n",
    "# or an upper case letter (A-Z), and replace it with a space\n",
    "\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      ex1.get_text() )  # The text to search\n",
    "print letters_only[:50] + '\\n'\n",
    "\n",
    "# Now do tokenisation : convert to all lowercase and run .split\n",
    "\n",
    "lower_case = letters_only.lower()        # Convert to lower case\n",
    "words = lower_case.split()               # Split into words\n",
    "\n",
    "print words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get rid of stopwords with the NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()  # Download text data sets, including stop words\n",
    "# Remove stop words from \"words\"\n",
    "words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
